= Tuning

The following sections provide a synopsis of Elasticsearch configurations. Prior
to deployment, we strongly recommend reading
https://www.elastic.co/guide/en/elasticsearch/guide/current/index.html[Elastic's documentation]
on production deployment.

== JVM 

The JVM vendor and version must be the same for the Elasticsearch server and the
@product@ server. In general, you should allocate 45 percent of the available
system memory to Elasticsearch, up to a maximum of 31 GB. Configure heap sizing
by setting the `ES_HEAP_SIZE` environment variable.

== File System 

Configure your operating system for at least 64,000 file descriptors (the
default Linux value is 1024). Since Elasticsearch uses NioFS and MMapFS, ensure
there is sufficient virtual memory available for memory-mapped files. Consult
your system administrator for information on how to configure these values.

== CPU

We recommend allocating at least eight total CPU cores to the Elasticsearch
engine, assuming only one Elasticsearch JVM is running on the machine. 

== Memory

At least 16 GB of memory is recommended, with 64 GB preferred. The precise
memory allocation required depends on how much data is indexed. For index sizes
500 GB to 1 TB, 64 GB of memory suffices. 

== Disk

Search engines store their indexes on disk, so disk I/O capacity can impact
search performance. Deploy Elasticsearch on SSD whenever possible. Otherwise use
high-performance traditional hard disks (for example, 15k RPM). In either case,
consider using RAID 0.

Avoid using Network Attached Storage (NAS) whenever possible as the network
overhead can be large. If you're using public cloud infrastructure like Amazon
Web Services, use instance local storage instead of network storage, such as
Elastic Block Store (EBS). 

Maintain 25 percent more disk capacity than the total size of your indexes. If
your index is 60 GB, make sure you have at least 75 GB of disk space available.
To estimate the disk space you need, you can index a representative sample of
your production content and multiply that size by the fraction of your
production content that it represents. For example, index 25 percent of your
production content and then multiply the resulting index size by four. Keep in
mind that indexing a 1 MB file doesn't result in 1 MB of disk space in the
search index. 

== Cluster 

While @product@ can work with an Elasticsearch cluster comprised of one or two
nodes, the minimum cluster size recommended by Elastic for fault tolerance is
three nodes.

Proper scaling and tuning of an Elasticsearch cluster primarily depends on the
type of indexes it holds and how they're intended to be used. Since @product@ is
a flexible development platform, no two applications index and search for data
in exactly the same way. Read the
https://www.elastic.co/guide/en/elasticsearch/guide/master/distributed-cluster.html[definitive Elasticsearch guide],
and understand the differences between
https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-indexing-speed.html[indexing-intensive applications]
and
https://www.elastic.co/guide/en/elasticsearch/reference/master/tune-for-search-speed.html[search-intensive applications].
Then you'll be able to predict usage patterns for your @product@ indexes and
design the optimally scaled and tuned cluster.

Once you determine the appropriate number of shards and replicas, configure them
in the Liferay Connector to Elasticsearch module, using these settings:

* `indexNumberOfReplicas` corresponds to Elasticsearch's `number_of_replicas`
  property.
* `indexNumberOfShards` corresponds to Elasticsearch's `number_of_shards`
  property.

== Network

Elasticsearch relies on clustering and sharding to deliver fast, accurate search
results, and thus requires a fast and reliable network. Most modern data centers
provide 1 GbE or 10 GbE between machines. 

Elasticsearch doesn't support multi-data center deployments.

